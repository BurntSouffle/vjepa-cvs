# Experiment 4: Attention Pooling + Balanced Sampling
# ====================================================
# Purpose: Test if balanced sampling helps with CVS class imbalance
# Target: RTX 3080 12GB (Windows)
#
# Changes from exp2:
#   - Sampling: WeightedRandomSampler with class_balanced strategy
#   - Oversamples positive examples to balance class distribution
#
# Dataset Statistics (from analysis):
#   - C1: 14.6% positive (5.86x imbalance)
#   - C2: 10.5% positive (8.55x imbalance) - most rare
#   - C3: 16.8% positive (4.95x imbalance)
#   - 73.9% samples are all-negative
#
# Hypothesis: Balanced sampling will improve mAP by ensuring the model
# sees positive examples more frequently during training.

# Paths (Windows local)
data:
  endoscapes_root: "C:/Users/sufia/Documents/Uni/Masters/DISSERTATION/endoscapes"
  sages_root: "C:/Users/sufia/Documents/Uni/Masters/DISSERTATION/sages_cvs_challenge_2025_r1"
  metadata_csv: "all_metadata.csv"
  train_vids: "train_vids.txt"
  val_vids: "val_vids.txt"
  test_vids: "test_vids.txt"
  results_dir: "C:/Users/sufia/Documents/Uni/Masters/DISSERTATION/vjepa/results/exp4_balanced_sampling"
  dataset_type: "endoscapes"

# Model - Same as exp2 (frozen backbone + attention pooling)
model:
  name: "facebook/vjepa2-vitl-fpc16-256-ssv2"
  freeze_backbone: true
  unfreeze_last_n_layers: 0
  hidden_dim: 1024
  classifier_hidden: 512
  num_classes: 3
  dropout: 0.5
  pooling_type: "attention"
  head_type: "mlp"
  attention_heads: 8
  attention_dropout: 0.1

# Data loading
dataset:
  num_frames: 16
  frame_step: 25
  resolution: 256
  augment_train: true
  horizontal_flip_prob: 0.5
  sages_val_ratio: 0.2

# Balanced Sampling (key change!)
sampling:
  balanced: true                    # Enable WeightedRandomSampler
  strategy: "class_balanced"        # Options: "class_balanced", "any_positive", "rare_combo"
                                    # - class_balanced: Weight by inverse class frequency (recommended)
                                    # - any_positive: Oversample samples with any positive label
                                    # - rare_combo: Oversample rare label combinations

# Training - Same as exp2
training:
  batch_size: 32
  gradient_accumulation_steps: 1
  num_workers: 4
  mixed_precision: true
  epochs: 15
  optimizer: "adamw"
  learning_rate: 5.0e-4
  weight_decay: 0.1
  scheduler: "cosine"
  warmup_epochs: 2
  min_lr: 1.0e-6
  early_stopping: true
  patience: 5
  grad_clip: 1.0

# Loss - Standard BCE (balanced sampling handles imbalance)
loss:
  type: "bce_with_logits"
  use_class_weights: false
  pos_weight: [1.0, 1.0, 1.0]

# Evaluation
evaluation:
  metrics: ["mAP", "AP_per_class", "balanced_accuracy", "f1"]
  threshold: 0.5

# Logging
logging:
  log_every_n_steps: 10
  save_every_n_epochs: 1

# Reproducibility
seed: 42

# Experiment metadata
experiment:
  name: "exp4_balanced_sampling"
  description: "Frozen V-JEPA + attention pooling + balanced sampling"
  hypothesis: "Balanced sampling improves CVS classification by increasing positive example frequency"
  baseline: "exp2_local_attention"
  changes:
    - "Sampling: Random shuffle -> WeightedRandomSampler"
    - "Strategy: class_balanced (inverse frequency weighting)"
